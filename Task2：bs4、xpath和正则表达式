2.1 BeautifulSoup：BeautifulSoup 是一个HTML/XML 的解析器，主要用于解析和提取 HTML/XML 数据
2.1.1 Beautiful Soup库的理解： Beautiful Soup库是解析、遍历、维护“标签树”的功能库，对应一个HTML/XML文档的全部内容
2.1.2 BeautifulSoup类的基本元素:
Tag 标签，最基本的信息组织单元，分别用<>和</>标明开头和结尾；
Name 标签的名字，<p>…</p>的名字是'p'，格式：<tag>.name;
Attributes 标签的属性，字典形式组织，格式：<tag>.attrs;
NavigableString 标签内非属性字符串，<>…</>中字符串，格式：<tag>.string;
Comment 标签内字符串的注释部分，一种特殊的Comment类型;
导入库：
import requests
from bs4 import BeautifulSoup
import bs4
#从网络上获取大学排名网页内容
url='http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html'
r=requests.get(url)
schools=r.text
print(schools)
#提取网页内容中信息到合适的数据结构（二维数组）
r.encoding = r.apparent_encoding#设置默认编码
soup=BeautifulSoup(r.text,'html.parser')#转bs4，慢
soup.prettify()
#利用数据结构展示并输出结果
schoollist=[['排名','学校','总分']]
for school in soup.find_all("tr","alt"):
    detaillist=[]
    for detail in school.children:
        detaillist.append(detail.text)
    schoollist.append([detaillist[0],detaillist[1],detaillist[3]])
schoollist[0:31]
2.2 xpath
2.2.1 学习xpath，使用lxml+xpath提取内容。
2.2.2 使用xpath提取丁香园论坛的回复内容。
2.2.3 抓取丁香园网页：http://www.dxy.cn/bbs/thread/626626#626626 
#利用Xpath表达式获取user和content（完成xpath的语句）
user = tree.xpath('//div[@class="auth"]/a/text()')#text()看作节点直接调用
print(user)
content = tree.xpath('//td[@class="postbody"]')#string(.)看作路径，需要.xpath二次“查询”
print(content)
2.3 学习正则表达式 re
