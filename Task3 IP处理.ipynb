{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "如何应对IP被封的问题，有几种套路：\n",
    "修改请求头，模拟浏览器（而不是代码去直接访问）去访问\n",
    "采用代理IP并轮换\n",
    "设置访问时间间隔\n",
    "\n",
    "如何获取代理IP地址：\n",
    "从该网站获取： https://www.xicidaili.com/\n",
    "inspect -> 鼠标定位：\n",
    "要获取的代理IP地址，属于class = \"odd\"标签的内容：代码如下，获取的代理IP保存在proxy_ip_list列表中\n",
    "使用代理\n",
    "proxies的格式是一个字典：\n",
    "{‘http’: ‘http://IP:port‘,‘https’:'https://IP:port‘}\n",
    "把它直接传入requests的get方法中即可\n",
    "web_data = requests.get(url, headers=headers, proxies=proxies)\n",
    " \n",
    "确认代理IP地址有效性\n",
    "无论是免费还是收费的代理网站，提供的代理IP都未必有效，我们应该验证一下，有效后，再放入我们的代理IP池中，以下通过几种方式：访问网站，得到的返回码是200真正的访问某些网站，获取title等，验证title与预计的相同访问某些可以提供被访问IP的网站，类似于“查询我的IP”的网站，查看返回的IP地址是什么验证返回码\n",
    "\n",
    "关于http和https代理\n",
    "可以看到proxies中有两个键值对：\n",
    "{‘http’: ‘http://IP:port‘,‘https’:'https://IP:port‘}\n",
    "其中 HTTP 代理，只代理 HTTP 网站，对于 HTTPS 的网站不起作用，也就是说，用的是本机 IP，反之亦然。\n",
    "我刚才使用的验证的网站是https://jsonip.com, 是HTTPS网站所以探测到的有效代理中，如果是https代理，则返回的是代理地址\n",
    "如果是http代理，将使用本机IP进行访问，返回的是我的公网IP地址\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    def check_ip(proxies_list):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#代码实现\n",
    "def send_request(page):\n",
    "    print('=========正在抓取第{}页=========='.format(page))\n",
    "    #发生请求，响应数据的方法\n",
    "    base_url = 'https://www.kuaidaili.com/free/inha/{}/'.format(page)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}\n",
    "    response=requests.get(base_url,headers=headers)\n",
    "    data=response.text\n",
    "    #with open('D:/python/代理.html','wb') as f:\n",
    "        #f.write(data)\n",
    "    time.sleep(1)  #爬取速度太快，需要休息一秒。不然反应不过来\n",
    "    return data\n",
    "def parse_data(data):\n",
    "    # 解析数据\n",
    "    #1 数据转换\n",
    "    html_data=parsel.Selector(data)\n",
    "    print(html_data)\n",
    "    #数据解析\n",
    "    parse_list=html_data.xpath('//table[@class=\"table table-bordered table-striped\"]/tbody/tr')\n",
    "    print(parse_list)\n",
    "    return parse_list\n",
    " def check_ip(proxies_list):\n",
    "    '检测代理ip的方法'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}\n",
    "    can_use=[]\n",
    "    for proxies in proxies_list:\n",
    "        try:\n",
    "            response = requests.get('https://www.baidu.com', headers=headers,proxies=proxies,timeout=0.1)\n",
    "            if response.status_code==200:\n",
    "                can_use.append(proxies)\n",
    "        except:\n",
    "            continue\n",
    "    print(can_use)\n",
    "    return can_use\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    proxies_list=[]\n",
    "    for page in range(1,5):\n",
    "        data=send_request(page)\n",
    "        parse_list=parse_data(data)\n",
    "        for tr in parse_list:\n",
    "            proxies_dict={}\n",
    "            http_type=tr.xpath('./td[4]/text()').extract_first()\n",
    "            ip_num=tr.xpath('./td[1]/text()').extract_first()\n",
    "            port_num=tr.xpath('./td[4]/text()').extract_first()\n",
    "            proxies_dict[http_type]=ip_num + \":\" + port_num\n",
    "            proxies_list.append(proxies_dict)\n",
    "    print('获取到的ip数量:',len(proxies_list),'个')\n",
    "    #print(proxies_dict)\n",
    "    can_use=check_ip(proxies_list)\n",
    "    print('能用的代理ip',can_use)\n",
    "    print('能用的代理ip数量',len(can_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selenium\n",
    "Selenium是一个web的自动化测试工具，最初是为网站自动化测试而开发的，Selenium可以直接运行在浏览器上，它支持所有主流的浏览器（包括phantomJS这些无界面的浏览器），可以接受指令，让浏览器自动加载页面。获取需要的数据，甚至页面截屏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本代码\n",
    "#1.创建浏览器对象\n",
    "driver=webdriver.Chrome()\n",
    "#2请求页面\n",
    "driver.get('https://www.baidu.com/')\n",
    "#3页面的基本操作（点击，输入）\n",
    "driver.find_element_by_id('kw').send_keys('元尊')   #输入\n",
    "driver.find_element_by_id('su').click()         #点击\n",
    "#4页面截屏\n",
    "time.sleep(2)\n",
    "driver.save_screenshot('yuanzu.png')\n",
    "#5获取渲染之后的数据\n",
    "print(driver.page_source)                  #获取的是F12中elements的数据而不是源代码数据\n",
    "#6还可以查看请求页面的cookies值\n",
    "print(driver.get_cookies())\n",
    "#7查看当然的url路径\n",
    "print(driver.current_url)\n",
    "#8关闭浏览器\n",
    "driver.close()    #关闭页面\n",
    "driver.quit()     #关闭浏览器\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「地球上最后一个直男」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/weixin_45568353/java/article/details/105706382"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
